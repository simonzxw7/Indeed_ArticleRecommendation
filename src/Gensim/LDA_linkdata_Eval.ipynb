{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim LDA Topic Modelling Evaluation on Link data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Libraries...Just a moment please!...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/gnx/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/gnx/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from pre_process import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path for the Source data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/gnx/MDS/Project-Indeed/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation specific variable declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "art_train = load_data(f\"{path}article.json\")\n",
    "art_test = load_data(f\"{path}pred_article.json\")\n",
    "all_article = pd.concat([art_train, art_test])\n",
    "cp_train = load_data(f\"{path}careerpathpage.json\")\n",
    "cl_train = load_data(f\"{path}coverletter.json\")\n",
    "res_train = load_data(f\"{path}resumesamplepage.json\")\n",
    "\n",
    "#Creating content title column which is a combination of title and content\n",
    "all_article[\"cont_title\"] = all_article[\"contentTitle\"] + \" \" +all_article[\"content\"]\n",
    "art_test[\"cont_title\"] = art_test[\"contentTitle\"] + \" \" +art_test[\"content\"]\n",
    "cp_train[\"cont_title\"] = cp_train[\"h1\"] + \" \" + cp_train[\"primaryContent\"]\n",
    "cl_train[\"cont_title\"] = cl_train[\"title\"] + \" \" + cl_train[\"contentA\"] + \" \" +cl_train[\"contentB\"]\n",
    "res_train[\"cont_title\"] = res_train[\"title\"] + \" \" + res_train[\"contentA\"] +\" \"+res_train[\"contentB\"]\n",
    "\n",
    "#Removing hyperlinks and html tags from the corpus\n",
    "rltd_arts, all_article = get_corpus(all_article, \"cont_title\")\n",
    "art_test = remove_hyperlinks_html_tags(art_test, \"cont_title\")\n",
    "cp_train = remove_hyperlinks_html_tags(cp_train, \"cont_title\")\n",
    "cl_train = remove_hyperlinks_html_tags(cl_train, \"cont_title\")\n",
    "res_train  = remove_hyperlinks_html_tags(res_train, \"cont_title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creating a list of cont_title, titles and url_routes\n",
    "cont = all_article[\"cont_title\"].tolist() + cp_train[\"cont_title\"].tolist() + cl_train[\"cont_title\"].tolist() + res_train[\"cont_title\"].tolist()\n",
    "all_title = all_article[\"contentTitle\"].tolist() + cp_train[\"h1\"].tolist() + cl_train[\"title\"].tolist() + res_train[\"title\"].tolist()\n",
    "url_route = all_article[\"urlRoute\"].tolist() + cp_train[\"urlRoute\"].tolist() + cl_train[\"urlRoute\"].tolist() + res_train[\"urlRoute\"].tolist()\n",
    "\n",
    "#Getting all document ids\n",
    "art_train_ids = [id_[\"$oid\"] for id_ in art_train[\"_id\"].tolist()]\n",
    "art_test_ids = [id_[\"$oid\"] for id_ in art_test[\"_id\"].tolist()]\n",
    "cp_train_ids = [id_[\"$oid\"] for id_ in cp_train[\"_id\"].tolist()]\n",
    "cl_train_ids = [id_[\"$oid\"] for id_ in cl_train[\"_id\"].tolist()]\n",
    "res_train_ids = [id_[\"$oid\"] for id_ in res_train[\"_id\"].tolist()]\n",
    "all_ids = art_train_ids + art_test_ids + cp_train_ids + cl_train_ids + res_train_ids\n",
    "\n",
    "#We are concatenating category and url column for loading link data and avoiding any duplicates \n",
    "all_article[\"cat_url\"] = all_article[\"category\"]+ \"|\" + all_article[\"urlRoute\"] \n",
    "cp_train[\"cat_url\"] = \"careers|\" + cp_train[\"urlRoute\"]\n",
    "cl_train[\"cat_url\"] = \"career-advice|\" + cl_train[\"urlRoute\"]\n",
    "res_train[\"cat_url\"] = res_train[\"category\"]+ \"|\" + res_train[\"urlRoute\"] \n",
    "\n",
    "#Creating a list of all category url data\n",
    "cat_url = all_article[\"cat_url\"].tolist() + cp_train[\"cat_url\"].tolist() + cl_train[\"cat_url\"].tolist() + res_train[\"cat_url\"].tolist()\n",
    "\n",
    "#Creating respective dictionary required for processing the link data\n",
    "# i2title_lookup = {i:title for i, title in enumerate(all_title)}\n",
    "url2i_lookup = {url:i for i, url in enumerate(cat_url)}\n",
    "id2index = {id:i for i, id in enumerate(all_ids)}\n",
    "id2index_rev = {i:id for i, id in enumerate(all_ids)}\n",
    "id2title = {id:title for id, title in zip(all_ids, all_title)}\n",
    "# title2i_lookup = {title:i for i, title in enumerate(all_title)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(all_ids)) == len(set(cat_url)) == len(set(url2i_lookup)) == len(set(id2title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of related articles: 14862\n"
     ]
    }
   ],
   "source": [
    "print(\"# of related articles:\", len(rltd_arts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic distribution embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"{path}pred_article.json\", encoding=\"utf-8\")\n",
    "test_train = []\n",
    "for line in f:\n",
    "    test_train.append(json.loads(line))\n",
    "test_train = pd.DataFrame(pd.DataFrame(test_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rltd_arts, art_train = get_corpus(art_train, \"content\")\n",
    "cl_train = remove_hyperlinks_html_tags(cl_train, \"contentA\")\n",
    "res_train  = remove_hyperlinks_html_tags(res_train, \"contentA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_train  = remove_hyperlinks_html_tags(cp_train, \"primaryContent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "def strip_newline(series):\n",
    "    \"\"\"\n",
    "    stripping out new line\n",
    "    \"\"\"                    \n",
    "    return [review.replace('\\n','') for review in series]\n",
    "def sent_to_words(sentences):\n",
    "    \"\"\"\n",
    "    Converting sentence to words\n",
    "    \"\"\"                \n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "        \n",
    "def remove_stopwords(texts):\n",
    "    \"\"\"\n",
    "    Used for removing stopwords\n",
    "    \"\"\"            \n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    \"\"\"\n",
    "    Find the bigrams in the content of the article\n",
    "    \"\"\"        \n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod\n",
    "\n",
    "def get_bigram(df):\n",
    "    if 'content' in df:\n",
    "        df_content = strip_newline(df.content)\n",
    "    elif 'contentA' in df:\n",
    "        df_content = df['contentA'] + ' ' + df['contentB']\n",
    "    elif 'primaryContent' in df:\n",
    "        df_content = df['primaryContent']\n",
    "    words = list(sent_to_words(df_content))\n",
    "    words = remove_stopwords(words)\n",
    "    bigram = bigrams(words)\n",
    "    bigram = [bigram[review] for review in words]\n",
    "    return bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_bigram = get_bigram(art_train)\n",
    "cp_bigram = get_bigram(cp_train)\n",
    "cl_bigram = get_bigram(cl_train)\n",
    "res_bigram = get_bigram(res_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on new articles\n",
    "test_art_bigram = get_bigram(test_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the model (same parameters we used for best models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "train_dict = Dictionary(art_bigram)\n",
    "train_corpus = [train_dict.doc2bow(text) for text in art_bigram]\n",
    "lda_30 = gensim.models.LdaModel(train_corpus,\n",
    "                            num_topics=30,\n",
    "                            id2word=train_dict,\n",
    "                            chunksize=100,\n",
    "                            random_state=10,\n",
    "                            passes=20,\n",
    "                            alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_corpus = [train_dict.doc2bow(text) for text in cp_bigram]\n",
    "cl_corpus = [train_dict.doc2bow(text) for text in cl_bigram]\n",
    "res_corpus = [train_dict.doc2bow(text) for text in res_bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on new articles\n",
    "test_corpus = [train_dict.doc2bow(text) for text in test_art_bigram]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Topic distribution embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlRoute_set = set()\n",
    "urlRoute_list = []\n",
    "for urlRoute in art_train['urlRoute'].tolist():\n",
    "    urlRoute_set.add(urlRoute)\n",
    "    urlRoute_list.append(urlRoute)\n",
    "for urlRoute in cp_train['urlRoute'].tolist():\n",
    "    urlRoute_set.add(urlRoute)\n",
    "    urlRoute_list.append(urlRoute)\n",
    "for urlRoute in cl_train['urlRoute'].tolist():\n",
    "    urlRoute_set.add(urlRoute)\n",
    "    urlRoute_list.append(urlRoute)\n",
    "for urlRoute in res_train['urlRoute'].tolist():\n",
    "    urlRoute_set.add(urlRoute)\n",
    "    urlRoute_list.append(urlRoute)\n",
    "for urlRoute in test_train['urlRoute'].tolist():\n",
    "    urlRoute_set.add(urlRoute)\n",
    "    urlRoute_list.append(urlRoute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the best model from above to generate the document distributions over the 30 topics. Frist thing we need to do is to pad those topics with 0 probability, so that the matrix we come up with will have consistant dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the document distributions over all the (30) topics\n",
    "def padding_matrix(model, train_corpus):\n",
    "    padding_dist_matrix = []\n",
    "    for i, dist in enumerate(model.get_document_topics(train_corpus)):\n",
    "        padding_dist_row = []\n",
    "        if len(dist) < 30:\n",
    "            dist_id = [topic_id for topic_id, prob in dist]\n",
    "            dist_id_prob_dict = {topic_id:prob for topic_id, prob in dist}\n",
    "            for i in range(30):\n",
    "                if i not in dist_id:\n",
    "                    padding_dist_row.append(0)\n",
    "                elif i in dist_id:\n",
    "                    padding_dist_row.append(dist_id_prob_dict[i])\n",
    "            padding_dist_matrix.append(padding_dist_row)\n",
    "        else:\n",
    "            prob_list = [prob for topic_id, prob in dist]\n",
    "            padding_dist_matrix.append(prob_list)\n",
    "    return padding_dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_padding_matrix = padding_matrix(lda_30, train_corpus)\n",
    "cp_padding_matrix = padding_matrix(lda_30, cp_corpus)\n",
    "cl_padding_matrix = padding_matrix(lda_30, cl_corpus)\n",
    "res_padding_matrix = padding_matrix(lda_30, res_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on new articles\n",
    "test_padding_matrix = padding_matrix(lda_30, test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_urlRoute = [art_train['urlRoute'].tolist(), cp_train['urlRoute'].tolist(), cl_train['urlRoute'].tolist(), res_train['urlRoute'].tolist(), test_train['urlRoute'].tolist()]\n",
    "general_embedding_dict = [art_padding_matrix, cp_padding_matrix, cl_padding_matrix, res_padding_matrix, test_padding_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlRoute_embedding_dict = defaultdict(list)\n",
    "count = 0\n",
    "for i, matrix in enumerate(general_embedding_dict):\n",
    "    for j, doc_embedding in enumerate(matrix):\n",
    "        urlRoute_embedding_dict[general_urlRoute[i][j]].append(general_embedding_dict[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sure the embedding is on the right order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlRoute_embeddings = defaultdict(list)\n",
    "count = 0\n",
    "for urlRoute in urlRoute_list:\n",
    "    \n",
    "    if len(urlRoute_embedding_dict[urlRoute]) == 1:\n",
    "        urlRoute_embeddings[urlRoute] = urlRoute_embedding_dict[urlRoute]\n",
    "        count += 1\n",
    "    elif len(urlRoute_embedding_dict[urlRoute]) == 2:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_rep = []\n",
    "for embeddings in urlRoute_embedding_dict:\n",
    "    row_embedding = []\n",
    "    for embedding in urlRoute_embedding_dict[embeddings]:\n",
    "        row_embedding.append(embedding)\n",
    "    embedding_rep.extend(row_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16281, 30)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_rep = np.array(embedding_rep)\n",
    "embedding_rep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity scores for topic distribution embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16281it [01:25, 190.45it/s]\n"
     ]
    }
   ],
   "source": [
    "np_rep = np.zeros([len(embedding_rep), len(embedding_rep)]) \n",
    "# numpy vector representation on cos_sim\n",
    "for i, row in tqdm(enumerate(np_rep)):\n",
    "\n",
    "    sent1 = embedding_rep[i]\n",
    "    sent2_list = embedding_rep\n",
    "    cosine_sim = sklearn.metrics.pairwise.cosine_similarity([sent1], sent2_list)\n",
    "    np_rep[i] = cosine_sim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.14060841, 0.2673521 , ..., 0.14129131, 0.5961785 ,\n",
       "        0.90125181],\n",
       "       [0.14060841, 1.        , 0.03289206, ..., 0.05985334, 0.19436421,\n",
       "        0.16844442],\n",
       "       [0.2673521 , 0.03289206, 1.        , ..., 0.05523276, 0.44670024,\n",
       "        0.19337641],\n",
       "       ...,\n",
       "       [0.14129131, 0.05985334, 0.05523276, ..., 1.        , 0.07953608,\n",
       "        0.16975831],\n",
       "       [0.5961785 , 0.19436421, 0.44670024, ..., 0.07953608, 1.        ,\n",
       "        0.58775112],\n",
       "       [0.90125181, 0.16844442, 0.19337641, ..., 0.16975831, 0.58775112,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Link Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Group by `sent1`\n",
    "2. Padding the dataframe with 0 visit articles.\n",
    "3. take the average cosine similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link files loaded to the system are:\n",
      " /Users/gnx/MDS/Project-Indeed/data/Pageview_matrix_20210511.csv\n"
     ]
    }
   ],
   "source": [
    "all_files = [f'{path}Pageview_matrix_20210511.csv']\n",
    "print(f\"Link files loaded to the system are:\\n {all_files[0]}\")\n",
    "\n",
    "linkdf = pd.read_csv(all_files[0], index_col=None, header=0)\n",
    "link1 = linkdf[\"link_1\"].apply(lambda x: \"/\".join(x.split(\"/\")[-2:]))\n",
    "link2 = linkdf[\"link_2\"].apply(lambda x: \"/\".join(x.split(\"/\")[-2:]))\n",
    "visit = linkdf[\"visitor_count\"]\n",
    "\n",
    "linkdf = pd.DataFrame(link1)\n",
    "linkdf[\"link_2\"] = link2\n",
    "linkdf[\"visitor_count\"] = visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_csv(df, type=\"ids\"):\n",
    "    \"\"\"\n",
    "    Transforming links in the link dataframe to title names\n",
    "    \"\"\"\n",
    "    links1 = []\n",
    "    links2 = []    \n",
    "    link_dict = defaultdict(list)\n",
    "    for i, (l1, l2, v) in enumerate(zip(df[\"link_1\"], df[\"link_2\"], df[\"visitor_count\"])):\n",
    "        if i % 1 == 0:\n",
    "            print(f\"Number of records processed : {i+1}\", end=\"\\r\")  \n",
    "        l1 = \"|\".join(l1.split(\"/\")[-2:])\n",
    "        l2 = \"|\".join(l2.split(\"/\")[-2:])\n",
    "        if l1 in cat_url and l2 in cat_url:\n",
    "            index = url2i_lookup[l1]\n",
    "            link_dict[\"link1\"].append(id2index_rev[index]) if type == \"ids\" else link_dict[\"link1\"].append(id2title[id2index_rev[index]])\n",
    "\n",
    "            index = url2i_lookup[l2]            \n",
    "            link_dict[\"link2\"].append(id2index_rev[index]) if type == \"ids\" else link_dict[\"link2\"].append(id2title[id2index_rev[index]])\n",
    "            link_dict[\"visit\"].append(int(v))                    \n",
    "        else:\n",
    "            continue\n",
    "    return link_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Link file ids:\n",
      "\n",
      "Number of records processed : 194374\r"
     ]
    }
   ],
   "source": [
    "print(\"Load Link file ids:\\n\")\n",
    "final_dict = link_csv(linkdf, \"ids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Link file titles:\n",
      "\n",
      "Number of records processed : 194374\r"
     ]
    }
   ],
   "source": [
    "print(\"Load Link file titles:\\n\")\n",
    "final_dict_ = link_csv(linkdf, \"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link1</th>\n",
       "      <th>link2</th>\n",
       "      <th>visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ceeecc3f6610e04a9091b36</td>\n",
       "      <td>5ceeecc3f6610e04a9091a90</td>\n",
       "      <td>2083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ceeecc3f6610e04a9091b1f</td>\n",
       "      <td>5ceeecc3f6610e04a9091ad8</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5ceeecc3f6610e04a9091b36</td>\n",
       "      <td>5ceeecc3f6610e04a9091ac2</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ceeecc3f6610e04a9091b1f</td>\n",
       "      <td>5ceeecc3f6610e04a9091a90</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ceeecc3f6610e04a9091b1f</td>\n",
       "      <td>5ceeecc3f6610e04a9091ac2</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190681</th>\n",
       "      <td>5ceeecc3f6610e04a9091a6a</td>\n",
       "      <td>5e68fba1ca80a8004009e2e7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190682</th>\n",
       "      <td>60944b81bd2003003b6cbac1</td>\n",
       "      <td>6094460cbd2003003b6cb96c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190683</th>\n",
       "      <td>60944783bd2003003b6cb9d6</td>\n",
       "      <td>6094475b01df0700449da41f</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190684</th>\n",
       "      <td>5e0fbce6faa4a8dd50bf3ca9</td>\n",
       "      <td>5e0fbbb2faa4a8dd50bf3990</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190685</th>\n",
       "      <td>5d9cf4786ad6fb21399acb19</td>\n",
       "      <td>5df11e4bac70c8d478e7dd57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190686 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           link1                     link2  visit\n",
       "0       5ceeecc3f6610e04a9091b36  5ceeecc3f6610e04a9091a90   2083\n",
       "1       5ceeecc3f6610e04a9091b1f  5ceeecc3f6610e04a9091ad8    428\n",
       "2       5ceeecc3f6610e04a9091b36  5ceeecc3f6610e04a9091ac2    322\n",
       "3       5ceeecc3f6610e04a9091b1f  5ceeecc3f6610e04a9091a90    307\n",
       "4       5ceeecc3f6610e04a9091b1f  5ceeecc3f6610e04a9091ac2    295\n",
       "...                          ...                       ...    ...\n",
       "190681  5ceeecc3f6610e04a9091a6a  5e68fba1ca80a8004009e2e7      2\n",
       "190682  60944b81bd2003003b6cbac1  6094460cbd2003003b6cb96c      2\n",
       "190683  60944783bd2003003b6cb9d6  6094475b01df0700449da41f      2\n",
       "190684  5e0fbce6faa4a8dd50bf3ca9  5e0fbbb2faa4a8dd50bf3990      2\n",
       "190685  5d9cf4786ad6fb21399acb19  5df11e4bac70c8d478e7dd57      2\n",
       "\n",
       "[190686 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df = pd.DataFrame.from_dict(final_dict)\n",
    "link_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link1</th>\n",
       "      <th>link2</th>\n",
       "      <th>visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>List of Weaknesses: 10 Things To Say in an Interview</td>\n",
       "      <td>39 Strengths and Weaknesses to Discuss in a Job Interview</td>\n",
       "      <td>2083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>125 Common Interview Questions and Answers (With Tips)</td>\n",
       "      <td>21 Job Interview Tips: How To Make a Great Impression</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>List of Weaknesses: 10 Things To Say in an Interview</td>\n",
       "      <td>How to Answer \"Tell Me About Yourself\" (Tips and Example Answers)</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125 Common Interview Questions and Answers (With Tips)</td>\n",
       "      <td>39 Strengths and Weaknesses to Discuss in a Job Interview</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125 Common Interview Questions and Answers (With Tips)</td>\n",
       "      <td>How to Answer \"Tell Me About Yourself\" (Tips and Example Answers)</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190681</th>\n",
       "      <td>Interview Question: \"What are You Passionate About?\"</td>\n",
       "      <td>10 Closing Statements to Use After an Interview</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190682</th>\n",
       "      <td>How to Get an Undergraduate Law Internship</td>\n",
       "      <td>8 Steps To Write a Daily Construction Report (With Tips)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190683</th>\n",
       "      <td>How To Become Construction Estimator in 3 Steps</td>\n",
       "      <td>How To Become an Art Therapist (With 7 Steps)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190684</th>\n",
       "      <td>How To Write an Application Letter (With Examples)</td>\n",
       "      <td>Self-Introduction Tips and Tricks (with Examples)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190685</th>\n",
       "      <td>How To Write a Federal Resume</td>\n",
       "      <td>Learn About Being an Advertising Manager</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190686 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         link1  \\\n",
       "0         List of Weaknesses: 10 Things To Say in an Interview   \n",
       "1       125 Common Interview Questions and Answers (With Tips)   \n",
       "2         List of Weaknesses: 10 Things To Say in an Interview   \n",
       "3       125 Common Interview Questions and Answers (With Tips)   \n",
       "4       125 Common Interview Questions and Answers (With Tips)   \n",
       "...                                                        ...   \n",
       "190681    Interview Question: \"What are You Passionate About?\"   \n",
       "190682              How to Get an Undergraduate Law Internship   \n",
       "190683         How To Become Construction Estimator in 3 Steps   \n",
       "190684      How To Write an Application Letter (With Examples)   \n",
       "190685                           How To Write a Federal Resume   \n",
       "\n",
       "                                                                    link2  \\\n",
       "0               39 Strengths and Weaknesses to Discuss in a Job Interview   \n",
       "1                   21 Job Interview Tips: How To Make a Great Impression   \n",
       "2       How to Answer \"Tell Me About Yourself\" (Tips and Example Answers)   \n",
       "3               39 Strengths and Weaknesses to Discuss in a Job Interview   \n",
       "4       How to Answer \"Tell Me About Yourself\" (Tips and Example Answers)   \n",
       "...                                                                   ...   \n",
       "190681                    10 Closing Statements to Use After an Interview   \n",
       "190682           8 Steps To Write a Daily Construction Report (With Tips)   \n",
       "190683                      How To Become an Art Therapist (With 7 Steps)   \n",
       "190684                  Self-Introduction Tips and Tricks (with Examples)   \n",
       "190685                           Learn About Being an Advertising Manager   \n",
       "\n",
       "        visit  \n",
       "0        2083  \n",
       "1         428  \n",
       "2         322  \n",
       "3         307  \n",
       "4         295  \n",
       "...       ...  \n",
       "190681      2  \n",
       "190682      2  \n",
       "190683      2  \n",
       "190684      2  \n",
       "190685      2  \n",
       "\n",
       "[190686 rows x 3 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_df_titles = pd.DataFrame.from_dict(final_dict_)\n",
    "link_df_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ratios(data, cosine_scores):\n",
    "    \"\"\"\n",
    "    Compute Visit to non-visit ratios\n",
    "    \"\"\"\n",
    "    visit = cosine_scores * data\n",
    "    visit_avg = np.sum(visit)/np.sum(data)\n",
    "    data_inv = 1 - data\n",
    "    non_visit = cosine_scores * data_inv\n",
    "    non_visit_avg = np.sum(non_visit)/np.sum(data_inv)\n",
    "\n",
    "    return visit_avg/non_visit_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_np_rep = np.mean(np_rep, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22591075, 0.16661671, 0.2104535 , ..., 0.20449436, 0.25713239,\n",
       "       0.24102602])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_np_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16281"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_rep[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ratio for topic distribution and Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_link_data(title, all_title, filter_cond, df, lookup1, lookup2):\n",
    "    \"\"\"\n",
    "    Generate link data in matrix for vectorization\n",
    "    \"\"\"    \n",
    "    link_data = np.zeros((len(title),len(all_title)))\n",
    "    print(link_data.shape)\n",
    "    df = df[df[\"visit\"]>filter_cond]\n",
    "    for i, (s1, s2, v) in enumerate(zip(df[\"link1\"], df[\"link2\"], df[\"visit\"])):\n",
    "        if i % 1 == 0:\n",
    "            print(f\"Number of records processed : {i+1}\", end=\"\\r\")  \n",
    "        link_data[lookup1[s1]][lookup2[s2]]=1\n",
    "    return link_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "general_train_df = [art_train, cp_train, cl_train, res_train, test_train]\n",
    "for df in general_train_df:\n",
    "    if 'content' in df:\n",
    "        content.extend(df['contentTitle'] + ' ' + df['content'])\n",
    "    elif 'contentA' in df:\n",
    "        content.extend(df['title'] + ' ' + df['contentA'] + ' ' + df['contentB'])\n",
    "    elif 'primaryContent' in df:\n",
    "        content.extend(df['h1'] + ' ' + df['primaryContent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "vecs = tfidf.fit_transform(content)\n",
    "tfidf_cosine_score = sklearn.metrics.pairwise.cosine_similarity(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16281, 16281)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_cosine_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ids allocated to train: 13024\n",
      "Number of ids allocated to test: 3257\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed=42)\n",
    "\n",
    "np.random.shuffle(all_ids)\n",
    "\n",
    "train = all_ids[:int(len(all_ids)*0.8)]\n",
    "test = all_ids[int(len(all_ids)*0.8):]\n",
    "\n",
    "print(f\"Number of ids allocated to train: {len(train)}\")\n",
    "print(f\"Number of ids allocated to test: {len(test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train title in link dataframe: 2975\n",
      "Number of test title in link dataframe: 707\n"
     ]
    }
   ],
   "source": [
    "train_links = set(link_df[\"link1\"]) & set(train)\n",
    "test_links = set(link_df[\"link1\"]) & set(test)\n",
    "\n",
    "print(f\"Number of train title in link dataframe: {len(train_links)}\")\n",
    "print(f\"Number of test title in link dataframe: {len(test_links)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_links) + len(test_links) == len(set(link_df[\"link1\"]) & set(train)) + len(set(link_df[\"link1\"]) & set(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ids : [13633  1921 12140 ... 15436 15768  2376]\n",
      "Train cosine scores shape: (13024, 16281)\n",
      "Train TF-IDF scores shape: (13024, 16281)\n"
     ]
    }
   ],
   "source": [
    "tcs = np.array([id2index[t]for t in train])\n",
    "print(f\"Train ids : {tcs}\")\n",
    "assert tcs.shape[0] == len(train)\n",
    "\n",
    "train_cs = np_rep[tcs]\n",
    "print(f\"Train cosine scores shape: {train_cs.shape}\")\n",
    "assert tcs.shape[0] == train_cs.shape[0]\n",
    "\n",
    "train_tf = tfidf_cosine_score[tcs]\n",
    "print(f\"Train TF-IDF scores shape: {train_tf.shape}\")\n",
    "assert tcs.shape[0] == train_cs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ids : [ 8551  3839 15427 ...   860 15795  7270]\n",
      "Test cosine scores shape: (3257, 16281)\n",
      "Test TF-IDF scores shape: (3257, 16281)\n"
     ]
    }
   ],
   "source": [
    "tcs = np.array([id2index[t]for t in test])\n",
    "print(f\"Test ids : {tcs}\")\n",
    "assert tcs.shape[0] == len(test)\n",
    "\n",
    "test_cs = np_rep[tcs]\n",
    "print(f\"Test cosine scores shape: {test_cs.shape}\")\n",
    "assert tcs.shape[0] == test_cs.shape[0]\n",
    "\n",
    "test_tf = tfidf_cosine_score[tcs]\n",
    "print(f\"Test TF-IDF scores shape: {test_tf.shape}\")\n",
    "assert tcs.shape[0] == test_tf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link1</th>\n",
       "      <th>link2</th>\n",
       "      <th>visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ddc2ce62961cc24bf00cc13</td>\n",
       "      <td>5e501b5ff3fb2a9df936da88</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ddc2ce62961cc24bf00cc13</td>\n",
       "      <td>5e5021f9f3fb2a9df936e4ce</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5ddc2ce62961cc24bf00cc13</td>\n",
       "      <td>5d4afe1eb58182000db71723</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ddc2ce62961cc24bf00cc13</td>\n",
       "      <td>5d9cf3b96ad6fb21399ac7c8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ceeea9e2102d07b1f75d98e</td>\n",
       "      <td>5ceeeaa02102d07b1f75da2a</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156779</th>\n",
       "      <td>5e973a16818be7003da8987a</td>\n",
       "      <td>5e28993f245be46e19a862f8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156780</th>\n",
       "      <td>5e973a16818be7003da8987a</td>\n",
       "      <td>5ceeecc3f6610e04a9091ac2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156781</th>\n",
       "      <td>5e973a16818be7003da8987a</td>\n",
       "      <td>5ddc2ce62961cc24bf00cc15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156782</th>\n",
       "      <td>5e973a16818be7003da8987a</td>\n",
       "      <td>5ceeecc3f6610e04a9091ad8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156783</th>\n",
       "      <td>5e973a16818be7003da8987a</td>\n",
       "      <td>5ceeecc3f6610e04a9091b1c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156784 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           link1                     link2  visit\n",
       "0       5ddc2ce62961cc24bf00cc13  5e501b5ff3fb2a9df936da88     16\n",
       "1       5ddc2ce62961cc24bf00cc13  5e5021f9f3fb2a9df936e4ce      4\n",
       "2       5ddc2ce62961cc24bf00cc13  5d4afe1eb58182000db71723      2\n",
       "3       5ddc2ce62961cc24bf00cc13  5d9cf3b96ad6fb21399ac7c8      2\n",
       "4       5ceeea9e2102d07b1f75d98e  5ceeeaa02102d07b1f75da2a      5\n",
       "...                          ...                       ...    ...\n",
       "156779  5e973a16818be7003da8987a  5e28993f245be46e19a862f8      2\n",
       "156780  5e973a16818be7003da8987a  5ceeecc3f6610e04a9091ac2      2\n",
       "156781  5e973a16818be7003da8987a  5ddc2ce62961cc24bf00cc15      2\n",
       "156782  5e973a16818be7003da8987a  5ceeecc3f6610e04a9091ad8      2\n",
       "156783  5e973a16818be7003da8987a  5ceeecc3f6610e04a9091b1c      2\n",
       "\n",
       "[156784 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ = defaultdict(list)\n",
    "\n",
    "for i in train_links:\n",
    "    l2 = link_df[link_df[\"link1\"]==i][\"link2\"]\n",
    "    visit = link_df[link_df[\"link1\"]==i][\"visit\"]\n",
    "    for j, (l2, v) in enumerate(zip(l2, visit)):\n",
    "        dict_[\"link1\"].append(i)\n",
    "        dict_[\"link2\"].append(l2)\n",
    "        dict_[\"visit\"].append(v)     \n",
    "train_df = pd.DataFrame.from_dict(dict_)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link1</th>\n",
       "      <th>link2</th>\n",
       "      <th>visit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5ddc2ce82961cc24bf00cc65</td>\n",
       "      <td>5fca8edd77a23d004b756717</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5ceeeaa02102d07b1f75da34</td>\n",
       "      <td>5ceeeaa02102d07b1f75da01</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5ceeeaa02102d07b1f75da34</td>\n",
       "      <td>5ceeea9e2102d07b1f75d959</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ceeeaa02102d07b1f75da34</td>\n",
       "      <td>5ceeeaa12102d07b1f75da78</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ceeeaa02102d07b1f75da34</td>\n",
       "      <td>5ceeeaa22102d07b1f75daab</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33897</th>\n",
       "      <td>5df3e978ac70c8d478e7e9e9</td>\n",
       "      <td>5ceeecc3f6610e04a9091afc</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33898</th>\n",
       "      <td>5e0fbc83faa4a8dd50bf3bb1</td>\n",
       "      <td>5df29f07ac70c8d478e7debc</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33899</th>\n",
       "      <td>5e0fbc83faa4a8dd50bf3bb1</td>\n",
       "      <td>5ceeecc3f6610e04a9091b03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33900</th>\n",
       "      <td>5e0fbc83faa4a8dd50bf3bb1</td>\n",
       "      <td>5ceeecc3f6610e04a9091a5e</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33901</th>\n",
       "      <td>5e0fbc83faa4a8dd50bf3bb1</td>\n",
       "      <td>5e20da745f555083f5d9cad3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33902 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          link1                     link2  visit\n",
       "0      5ddc2ce82961cc24bf00cc65  5fca8edd77a23d004b756717      4\n",
       "1      5ceeeaa02102d07b1f75da34  5ceeeaa02102d07b1f75da01      4\n",
       "2      5ceeeaa02102d07b1f75da34  5ceeea9e2102d07b1f75d959      3\n",
       "3      5ceeeaa02102d07b1f75da34  5ceeeaa12102d07b1f75da78      3\n",
       "4      5ceeeaa02102d07b1f75da34  5ceeeaa22102d07b1f75daab      3\n",
       "...                         ...                       ...    ...\n",
       "33897  5df3e978ac70c8d478e7e9e9  5ceeecc3f6610e04a9091afc      2\n",
       "33898  5e0fbc83faa4a8dd50bf3bb1  5df29f07ac70c8d478e7debc      4\n",
       "33899  5e0fbc83faa4a8dd50bf3bb1  5ceeecc3f6610e04a9091b03      3\n",
       "33900  5e0fbc83faa4a8dd50bf3bb1  5ceeecc3f6610e04a9091a5e      2\n",
       "33901  5e0fbc83faa4a8dd50bf3bb1  5e20da745f555083f5d9cad3      2\n",
       "\n",
       "[33902 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ = defaultdict(list)\n",
    "\n",
    "for i in test_links:\n",
    "    l2 = link_df[link_df[\"link1\"]==i][\"link2\"]\n",
    "    visit = link_df[link_df[\"link1\"]==i][\"visit\"]\n",
    "    for j, (l2, v) in enumerate(zip(l2, visit)):\n",
    "        dict_[\"link1\"].append(i)\n",
    "        dict_[\"link2\"].append(l2)\n",
    "        dict_[\"visit\"].append(v)    \n",
    "test_df = pd.DataFrame.from_dict(dict_)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(train_df[\"link1\"]) != set(test_df[\"link1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13024, 16281)\n",
      "Number of records processed : 4767\n",
      "\n",
      "filter condition: visit count > 5\n",
      "Ratio of visit to non visit:\n",
      "Topic distribution: 1.1785510766180431\n",
      "TF-IDF: 2.3204042911456417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=5\n",
    "train_lookup = {id:i for i, id in enumerate(train)}\n",
    "\n",
    "train_link_data = generate_link_data(train, all_ids, i, train_df, train_lookup, id2index)\n",
    "\n",
    "print(f\"\"\"\n",
    "\\nfilter condition: visit count > {i}\n",
    "Ratio of visit to non visit:\n",
    "Topic distribution: {compute_ratios(train_link_data, train_cs)}\n",
    "TF-IDF: {compute_ratios(train_link_data, train_tf)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3257, 16281)\n",
      "Number of records processed : 1365\n",
      "\n",
      "filter condition: visit count > 5\n",
      "Ratio of visit to non visit:\n",
      "Topic distribution: 1.2579866110610374\n",
      "TF-IDF: 2.3235231681007384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=5\n",
    "test_lookup = {id:i for i, id in enumerate(test)}\n",
    "\n",
    "test_link_data = generate_link_data(test, all_ids, i, test_df, test_lookup, id2index)\n",
    "print(f\"\"\"\n",
    "\\nfilter condition: visit count > {i}\n",
    "Ratio of visit to non visit:\n",
    "Topic distribution: {compute_ratios(test_link_data, test_cs)}\n",
    "TF-IDF: {compute_ratios(test_link_data, test_tf)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13024, 16281)\n",
      "Number of records processed : 156784\n",
      "\n",
      "filter condition: visit count > 0\n",
      "Ratio of visit to non visit:\n",
      "Topic distribution: 1.4147146175431986\n",
      "TF-IDF: 1.1535592876764207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "train_lookup = {id:i for i, id in enumerate(train)}\n",
    "\n",
    "train_link_data = generate_link_data(train, all_ids, i, train_df, train_lookup, id2index)\n",
    "\n",
    "print(f\"\"\"\n",
    "\\nfilter condition: visit count > {i}\n",
    "Ratio of visit to non visit:\n",
    "Topic distribution: {compute_ratios(train_link_data, train_cs)}\n",
    "TF-IDF: {compute_ratios(train_link_data, train_tf)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3257, 16281)\n",
      "Number of records processed : 33902\n",
      "\n",
      "filter condition: visit count > 0\n",
      "Ratio of visit to non visit:\n",
      "Topic distribution: 1.3395919218947\n",
      "TF-IDF: 1.2363551866243445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "# test_lookup = {title:i for i, title in enumerate(test)}\n",
    "test_lookup = {id:i for i, id in enumerate(test)}\n",
    "\n",
    "test_link_data = generate_link_data(test, all_ids, i, test_df, test_lookup, id2index)\n",
    "print(f\"\"\"\n",
    "\\nfilter condition: visit count > {i}\n",
    "Ratio of visit to non visit:\n",
    "Topic distribution: {compute_ratios(test_link_data, test_cs)}\n",
    "TF-IDF: {compute_ratios(test_link_data, test_tf)}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
